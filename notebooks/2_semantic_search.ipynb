{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebcba99-5bfb-42af-aaec-ede0dbc87108",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f43b39-2243-40d4-a76d-60aa12661e98",
   "metadata": {},
   "source": [
    "# Colab 환경 초기화 \n",
    "* local에서 실행시 불필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8af383c-15ec-42d9-997d-69af2d6086be",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0013c2b-41c5-40e1-824a-5e69673064bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: streamlit in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (1.31.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (7.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (15.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (4.10.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (3.1.42)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: jinja2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.21.1)\n",
      "Requirement already satisfied: toolz in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: datasets in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pinecone-client in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pinecone-client) (2024.2.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pinecone-client) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pinecone-client) (4.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: tiktoken in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Requirement already satisfied: PyPDF2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: sentence-transformers in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: requests in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: evaluate in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wlkim/anaconda3/envs/quick-start-guide-to-llms/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install streamlit\n",
    "!pip install datasets\n",
    "!pip install pinecone-client\n",
    "!pip install tiktoken\n",
    "!pip install PyPDF2\n",
    "!pip install sentence-transformers\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c9aa3d-6d6c-4950-b6fe-cc0553b4d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# 1-1. Google drive mount\n",
    "\n",
    "if IN_COLAB == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/quick-start-guide-to-llms/notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54eb8284-59ac-4304-819b-05d93bb75c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: /content/drive/MyDrive/Colab Notebooks/quick-start-guide-to-llms/notebooks\n"
     ]
    }
   ],
   "source": [
    "!cd \"/content/drive/MyDrive/Colab Notebooks/quick-start-guide-to-llms/notebooks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924ea2b-e103-4279-975c-92cb6eddde45",
   "metadata": {},
   "source": [
    "이 노트북은 최신 openai 패키지 버전을 사용하도록 업데이트되었습니다! 당시 1.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16c8ce-898f-4eb4-a679-fc61a9859634",
   "metadata": {},
   "source": [
    "# 2장: 독점 모델로 애플리케이션 시작하기\n",
    "* 독점 모델 개요\n",
    "* OpenAI + 임베딩 / GPT3 / ChatGPT 소개\n",
    "* 벡터 데이터베이스 소개\n",
    "* 벡터 데이터베이스, BERT 및 GPT3로 신경/의미 정보 검색 시스템 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12182ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0289c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB == True:\n",
    "    pinecone_key = \"PINECONE API KEY\"\n",
    "    openai_key=\"OPENAI API KEY\"\n",
    "else:\n",
    "    pinecone_key = os.environ.get('PINECONE_API_KEY')\n",
    "    openai_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    \n",
    "client = OpenAI(\n",
    "    api_key=openai_key\n",
    ")\n",
    "\n",
    "INDEX_NAME = 'semantic-search'\n",
    "NAMESPACE = 'default'\n",
    "ENGINE = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9befee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 소스 오류 수정\n",
    "# import pinecone\n",
    "# pinecone.init(api_key=pinecone_key, environment=\"us-west1-gcp\")\n",
    "\n",
    "from pinecone import Pinecone, PodSpec\n",
    "pinecone = Pinecone(api_key=pinecone_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf993a3-6d51-49f4-8968-60f654d6202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenAI API에서 임베딩 목록을 가져오는 헬퍼 함수\n",
    "def get_embeddings(texts, engine=ENGINE):\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=engine\n",
    "    )\n",
    "    \n",
    "    return [d.embedding for d in list(response.data)]\n",
    "\n",
    "def get_embedding(text, engine=ENGINE):\n",
    "    return get_embeddings([text], engine)[0]\n",
    "    \n",
    "len(get_embedding('hi')), len(get_embeddings(['hi', 'hello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea70672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 소스 오류 수정\n",
    "# https://docs.pinecone.io/docs/view-index-information\n",
    "# https://docs.pinecone.io/docs/create-an-index\n",
    "\n",
    "if not INDEX_NAME in pinecone.list_indexes().names():\n",
    "    pinecone.create_index(\n",
    "        INDEX_NAME, # 인덱스 이름\n",
    "        dimension=1536, # 벡터의 치수\n",
    "        metric='cosine', # 인덱스를 검색할 때 사용할 유사성 메트릭\n",
    "        spec=PodSpec(\n",
    "          environment=\"gcp-starter\"\n",
    "        )\n",
    "        # pod_type=\"p1\" # 파인콘 파드의 유형\n",
    "    )\n",
    "\n",
    "# 인덱스를 변수로 저장\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f2fdfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ae76cc4dfd345ecaeea9b8ba0d5c3437'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_hash(s):\n",
    "    # 입력 문자열의 MD5 해시를 16진수 문자열로 반환합니다.\n",
    "    return hashlib.md5(s.encode()).hexdigest()\n",
    "\n",
    "my_hash('I love to hash it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecd86f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_pinecone(text, engine=ENGINE):\n",
    "    # 현재 UTC 날짜 및 시간을 가져옵니다.\n",
    "    now = datetime.utcnow()\n",
    "    \n",
    "    # 지정된 엔진을 사용하여 입력 목록의 각 문자열에 대한 벡터 임베딩을 생성합니다.\n",
    "    embeddings = get_embeddings(texts, engine=engine)\n",
    "    \n",
    "    # 각 입력 문자열과 해당 벡터 임베딩에 대해 (해시, 임베딩, 메타데이터)의 튜플을 생성합니다.\n",
    "    # my_hash() 함수는 각 문자열에 대해 고유한 해시를 생성하는 데 사용되며, datetime.utcnow() 함수는 현재 UTC 날짜 및 시간을 생성하는 데 사용됩니다.\n",
    "    return [\n",
    "        (\n",
    "            my_hash(text), # my_hash() 함수를 사용하여 생성된 각 문자열에 대한 고유 ID\n",
    "            embedding, # 문자열의 벡터 임베딩\n",
    "            dict(text=text, date_uploaded=now) # 원본 텍스트와 현재 UTC 날짜 및 시간을 포함한 메타데이터의 사전입니다.\n",
    "        ) \n",
    "        for text, embedding in zip(texts, embeddings) # 각 입력 문자열과 해당 벡터 임베딩에 대해 반복합니다.\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c40d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e065c037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('49f68a5c8493ec2c0bf489821c21fc3b',\n",
       " [-0.030913319438695908,\n",
       "  -0.020414210855960846,\n",
       "  -0.019505759701132774,\n",
       "  -0.04178878664970398,\n",
       "  -0.024813713505864143,\n",
       "  0.024307576939463615,\n",
       "  -0.0179743692278862,\n",
       "  -0.017701834440231323,\n",
       "  -0.0065019200555980206,\n",
       "  -0.015910886228084564,\n",
       "  0.025890879333019257,\n",
       "  -0.006949656642973423,\n",
       "  -0.01790948025882244,\n",
       "  -0.011848808266222477,\n",
       "  0.011465960182249546,\n",
       "  0.01648191176354885,\n",
       "  0.038751959800720215,\n",
       "  0.0005187098286114633,\n",
       "  0.03221110627055168,\n",
       "  -0.008701670914888382,\n",
       "  -0.019635537639260292,\n",
       "  -0.0049056401476264,\n",
       "  -0.009298654273152351,\n",
       "  -0.014327583834528923,\n",
       "  -0.022867031395435333,\n",
       "  0.002483642427250743,\n",
       "  0.010051371529698372,\n",
       "  -0.01176445186138153,\n",
       "  0.0026069325394928455,\n",
       "  -0.026020657271146774,\n",
       "  0.014535229653120041,\n",
       "  0.0006987779634073377,\n",
       "  -0.035767048597335815,\n",
       "  -0.014963500201702118,\n",
       "  -0.009486833587288857,\n",
       "  -0.024748824536800385,\n",
       "  0.006988590583205223,\n",
       "  -0.02111501805484295,\n",
       "  0.01918131299316883,\n",
       "  -0.005687557626515627,\n",
       "  0.006128805689513683,\n",
       "  -0.0007223003776744008,\n",
       "  0.0014072892954573035,\n",
       "  -0.014392473734915257,\n",
       "  -0.023022765293717384,\n",
       "  -0.0060898722149431705,\n",
       "  0.0009684746037237346,\n",
       "  0.004071811214089394,\n",
       "  -0.012361434288322926,\n",
       "  0.01984318532049656,\n",
       "  0.015897907316684723,\n",
       "  0.007066457998007536,\n",
       "  -0.02974531054496765,\n",
       "  -0.01138809323310852,\n",
       "  -0.02006380818784237,\n",
       "  -0.007630995940417051,\n",
       "  -0.01513221301138401,\n",
       "  0.011238847859203815,\n",
       "  -0.010551019571721554,\n",
       "  -0.022659385576844215,\n",
       "  -0.010771643370389938,\n",
       "  0.005499378312379122,\n",
       "  -0.004879684187471867,\n",
       "  0.006060671992599964,\n",
       "  0.010421240702271461,\n",
       "  -0.008461580611765385,\n",
       "  0.023567836731672287,\n",
       "  -0.0010195750510320067,\n",
       "  0.00443843612447381,\n",
       "  0.0007908397819846869,\n",
       "  0.02142648585140705,\n",
       "  0.033820364624261856,\n",
       "  -0.004989996552467346,\n",
       "  -0.014249716885387897,\n",
       "  0.012062943540513515,\n",
       "  -0.007326015271246433,\n",
       "  -0.003565673716366291,\n",
       "  -0.00121748773381114,\n",
       "  -0.006187206134200096,\n",
       "  -0.00689125619828701,\n",
       "  0.025138162076473236,\n",
       "  -0.03138052299618721,\n",
       "  -0.016001731157302856,\n",
       "  0.017481209710240364,\n",
       "  0.008312334306538105,\n",
       "  0.016793381422758102,\n",
       "  -0.005077597219496965,\n",
       "  0.012854593805968761,\n",
       "  -0.01565132848918438,\n",
       "  -0.031873684376478195,\n",
       "  0.006398096680641174,\n",
       "  0.022996811196208,\n",
       "  0.013574866577982903,\n",
       "  0.01382144633680582,\n",
       "  -0.01108311302959919,\n",
       "  0.018324771896004677,\n",
       "  -0.011569783091545105,\n",
       "  0.01849348470568657,\n",
       "  -0.007403882686048746,\n",
       "  0.006284540519118309,\n",
       "  0.0008086843881756067,\n",
       "  0.008870383724570274,\n",
       "  0.0013967447448521852,\n",
       "  -0.005502622574567795,\n",
       "  -0.027902450412511826,\n",
       "  -0.020647812634706497,\n",
       "  -0.017416320741176605,\n",
       "  -0.01382144633680582,\n",
       "  0.016806360334157944,\n",
       "  -0.0015021900180727243,\n",
       "  -0.002910290379077196,\n",
       "  0.036519765853881836,\n",
       "  0.005548045504838228,\n",
       "  -0.034261614084243774,\n",
       "  -0.010401774197816849,\n",
       "  -0.007955443114042282,\n",
       "  0.0032201374415308237,\n",
       "  -0.0034066946245729923,\n",
       "  -0.0122056994587183,\n",
       "  -0.023204457014799118,\n",
       "  0.0045455037616193295,\n",
       "  0.0002054155629593879,\n",
       "  0.01550857163965702,\n",
       "  0.003345049684867263,\n",
       "  0.015690261498093605,\n",
       "  0.008072244003415108,\n",
       "  -0.02404801920056343,\n",
       "  -0.0052430653013288975,\n",
       "  0.0075790840201079845,\n",
       "  0.005009463056921959,\n",
       "  0.04817390441894531,\n",
       "  0.011751473881304264,\n",
       "  0.005191153381019831,\n",
       "  -0.007209214381873608,\n",
       "  -0.03356080874800682,\n",
       "  0.035403668880462646,\n",
       "  -0.024891581386327744,\n",
       "  0.02307467721402645,\n",
       "  -0.02397015132009983,\n",
       "  -0.032392799854278564,\n",
       "  -0.0056616016663610935,\n",
       "  0.03828475624322891,\n",
       "  -7.472422294085845e-05,\n",
       "  -0.017403341829776764,\n",
       "  -0.01382144633680582,\n",
       "  -0.01344508770853281,\n",
       "  0.015106257051229477,\n",
       "  -0.0029313794802874327,\n",
       "  -0.0014948899624869227,\n",
       "  -0.002105661667883396,\n",
       "  0.0015938463620841503,\n",
       "  0.0018509706715121865,\n",
       "  0.020102743059396744,\n",
       "  -0.0005466933362185955,\n",
       "  0.029304061084985733,\n",
       "  0.02067376859486103,\n",
       "  -0.012945439666509628,\n",
       "  -0.010765154846012592,\n",
       "  -0.010914400219917297,\n",
       "  -0.008760071359574795,\n",
       "  -0.0008090899791568518,\n",
       "  -0.003038447117432952,\n",
       "  0.023801438510417938,\n",
       "  -0.01062888652086258,\n",
       "  -0.003760341787710786,\n",
       "  0.01766289956867695,\n",
       "  0.01227707788348198,\n",
       "  0.027357378974556923,\n",
       "  0.012841615825891495,\n",
       "  -0.0018379928078502417,\n",
       "  0.013354242779314518,\n",
       "  0.019635537639260292,\n",
       "  -0.03039420396089554,\n",
       "  0.00531768798828125,\n",
       "  0.00046436491538770497,\n",
       "  0.01105066854506731,\n",
       "  0.015768129378557205,\n",
       "  0.01362677849829197,\n",
       "  -0.03042015992105007,\n",
       "  -0.04404693841934204,\n",
       "  -0.015313902869820595,\n",
       "  0.017351431772112846,\n",
       "  0.03273022174835205,\n",
       "  0.02958957478404045,\n",
       "  -0.009233764372766018,\n",
       "  0.014314605854451656,\n",
       "  0.029823176562786102,\n",
       "  0.004863461945205927,\n",
       "  0.01662466861307621,\n",
       "  -0.020258476957678795,\n",
       "  0.01550857163965702,\n",
       "  0.02899259328842163,\n",
       "  0.01685827039182186,\n",
       "  -0.006527875550091267,\n",
       "  -0.7010133862495422,\n",
       "  -0.031198833137750626,\n",
       "  -0.0045455037616193295,\n",
       "  -0.0019061267375946045,\n",
       "  0.020725680515170097,\n",
       "  0.043112531304359436,\n",
       "  0.026760397478938103,\n",
       "  0.021452441811561584,\n",
       "  -0.018259882926940918,\n",
       "  0.01596279814839363,\n",
       "  -0.007864597253501415,\n",
       "  -0.004506570287048817,\n",
       "  0.008247445337474346,\n",
       "  -0.014859677292406559,\n",
       "  0.005625912919640541,\n",
       "  0.007423349656164646,\n",
       "  -0.00034290002076886594,\n",
       "  -0.007494728080928326,\n",
       "  -0.011238847859203815,\n",
       "  0.002081328071653843,\n",
       "  -0.004146433901041746,\n",
       "  -0.003916076384484768,\n",
       "  -0.023399123921990395,\n",
       "  0.020777592435479164,\n",
       "  0.00929216481745243,\n",
       "  -0.005486400332301855,\n",
       "  -0.0022484182845801115,\n",
       "  -0.009298654273152351,\n",
       "  -0.019544692710042,\n",
       "  0.010239550843834877,\n",
       "  -0.013717623427510262,\n",
       "  0.011985075660049915,\n",
       "  0.012017520144581795,\n",
       "  -0.01029795128852129,\n",
       "  0.05985400080680847,\n",
       "  0.005129508674144745,\n",
       "  -0.004292435012757778,\n",
       "  0.020388254895806313,\n",
       "  0.006495431065559387,\n",
       "  0.049160223454236984,\n",
       "  -0.0007113502360880375,\n",
       "  -0.019337046891450882,\n",
       "  0.005252798553556204,\n",
       "  0.006274806801229715,\n",
       "  0.005768669303506613,\n",
       "  0.016871249303221703,\n",
       "  -0.009078029543161392,\n",
       "  -0.0015313903568312526,\n",
       "  0.009512788616120815,\n",
       "  -0.0009911858942359686,\n",
       "  0.010804088786244392,\n",
       "  -0.006703076884150505,\n",
       "  -0.012328989803791046,\n",
       "  0.018843887373805046,\n",
       "  0.00932460930198431,\n",
       "  -0.0027302224189043045,\n",
       "  0.02194560132920742,\n",
       "  -0.024385444819927216,\n",
       "  -0.005960093345493078,\n",
       "  0.02397015132009983,\n",
       "  0.00038690317887812853,\n",
       "  0.003088736440986395,\n",
       "  -0.01415887102484703,\n",
       "  -0.019233224913477898,\n",
       "  -0.013977181166410446,\n",
       "  0.01977829448878765,\n",
       "  -0.02195858024060726,\n",
       "  -0.009603634476661682,\n",
       "  -0.0008897961815819144,\n",
       "  -0.005937382113188505,\n",
       "  -0.013081707060337067,\n",
       "  0.019337046891450882,\n",
       "  -0.027435246855020523,\n",
       "  -0.016352133825421333,\n",
       "  0.002018061000853777,\n",
       "  0.02389228530228138,\n",
       "  0.012393878772854805,\n",
       "  -0.0060704052448272705,\n",
       "  -0.009142919443547726,\n",
       "  0.010070838034152985,\n",
       "  0.0013204996939748526,\n",
       "  -0.0024138863664120436,\n",
       "  -0.005505867302417755,\n",
       "  -0.011498405598104,\n",
       "  0.02419077605009079,\n",
       "  -0.026487860828638077,\n",
       "  -0.03363867476582527,\n",
       "  0.014366517774760723,\n",
       "  -0.0067290328443050385,\n",
       "  -0.0025631319731473923,\n",
       "  0.005489645060151815,\n",
       "  0.035844914615154266,\n",
       "  0.013062240555882454,\n",
       "  -0.020349321886897087,\n",
       "  0.006167739164084196,\n",
       "  0.009454388171434402,\n",
       "  -0.02051803469657898,\n",
       "  0.0029265128541737795,\n",
       "  -0.0032428486738353968,\n",
       "  -0.012711836956441402,\n",
       "  -0.007877575233578682,\n",
       "  0.0029394906014204025,\n",
       "  -0.0016603580443188548,\n",
       "  -0.0056388904340565205,\n",
       "  0.01670253649353981,\n",
       "  -0.003903098637238145,\n",
       "  -0.014444384723901749,\n",
       "  0.03984210267663002,\n",
       "  0.027513114735484123,\n",
       "  -0.020427189767360687,\n",
       "  -0.00248039816506207,\n",
       "  -0.001167198410257697,\n",
       "  -0.00781917478889227,\n",
       "  0.005408532917499542,\n",
       "  0.008240955881774426,\n",
       "  -0.03301573544740677,\n",
       "  -0.012121343985199928,\n",
       "  0.031562212854623795,\n",
       "  0.021608177572488785,\n",
       "  -0.015210079960525036,\n",
       "  0.005330665968358517,\n",
       "  -0.0036662521306425333,\n",
       "  0.02103715017437935,\n",
       "  -0.01648191176354885,\n",
       "  0.0014567674370482564,\n",
       "  0.01858432963490486,\n",
       "  -0.010447196662425995,\n",
       "  -0.0035624292213469744,\n",
       "  -0.031640082597732544,\n",
       "  0.007890553213655949,\n",
       "  0.013899313285946846,\n",
       "  -0.01138809323310852,\n",
       "  0.017792679369449615,\n",
       "  -0.020569946616888046,\n",
       "  0.014210782945156097,\n",
       "  -0.005976315587759018,\n",
       "  0.0012239767238497734,\n",
       "  -0.010797599330544472,\n",
       "  -0.00816957838833332,\n",
       "  -0.005165197886526585,\n",
       "  -0.002081328071653843,\n",
       "  0.0046915048733353615,\n",
       "  0.00011284675565548241,\n",
       "  -0.004626615438610315,\n",
       "  0.0019872384145855904,\n",
       "  -0.032237064093351364,\n",
       "  -0.0197004284709692,\n",
       "  -0.005090575199574232,\n",
       "  -0.01269885990768671,\n",
       "  0.004947818350046873,\n",
       "  0.0006780944531783462,\n",
       "  -0.0018574596615508199,\n",
       "  -0.010849511250853539,\n",
       "  0.018778998404741287,\n",
       "  0.03550748899579048,\n",
       "  -0.022049425169825554,\n",
       "  -0.0035040287766605616,\n",
       "  -0.021283729001879692,\n",
       "  -0.011303736828267574,\n",
       "  -2.144392601621803e-05,\n",
       "  0.003455361584201455,\n",
       "  0.022490672767162323,\n",
       "  -0.014937544241547585,\n",
       "  0.0020277942530810833,\n",
       "  0.0017763478681445122,\n",
       "  -0.027616936713457108,\n",
       "  -0.0016506245592609048,\n",
       "  0.023412102833390236,\n",
       "  0.0030546693596988916,\n",
       "  -0.038310714066028595,\n",
       "  0.01722165197134018,\n",
       "  -0.015833018347620964,\n",
       "  -0.006164494901895523,\n",
       "  0.0026945332065224648,\n",
       "  0.017779700458049774,\n",
       "  0.006167739164084196,\n",
       "  -0.0074493056163191795,\n",
       "  0.007462283130735159,\n",
       "  -0.001555723836645484,\n",
       "  -0.032911915332078934,\n",
       "  0.010771643370389938,\n",
       "  0.0021527064964175224,\n",
       "  -0.01066782046109438,\n",
       "  0.010129238478839397,\n",
       "  0.02105012722313404,\n",
       "  0.00805277656763792,\n",
       "  0.008870383724570274,\n",
       "  0.02560536563396454,\n",
       "  -0.01273130439221859,\n",
       "  0.010927378199994564,\n",
       "  0.007507706061005592,\n",
       "  0.020543990656733513,\n",
       "  -0.01714378409087658,\n",
       "  -0.0012961662141606212,\n",
       "  0.008208511397242546,\n",
       "  0.011329692788422108,\n",
       "  0.002527442993596196,\n",
       "  0.002790244994685054,\n",
       "  0.009201319888234138,\n",
       "  0.02389228530228138,\n",
       "  0.0420743003487587,\n",
       "  0.009441410191357136,\n",
       "  0.034339480102062225,\n",
       "  -0.011193424463272095,\n",
       "  -0.00970096793025732,\n",
       "  -0.026267237961292267,\n",
       "  0.001176120713353157,\n",
       "  -0.005703779868781567,\n",
       "  0.020543990656733513,\n",
       "  0.0162483099848032,\n",
       "  -0.005200887098908424,\n",
       "  -0.015249013900756836,\n",
       "  0.00868220441043377,\n",
       "  0.003932298626750708,\n",
       "  0.019142378121614456,\n",
       "  0.017727790400385857,\n",
       "  -0.008078732527792454,\n",
       "  0.012964906170964241,\n",
       "  -0.021024171262979507,\n",
       "  0.010343373753130436,\n",
       "  0.011933164671063423,\n",
       "  -0.011063646525144577,\n",
       "  0.014145893976092339,\n",
       "  -0.00013180663518141955,\n",
       "  0.004899151157587767,\n",
       "  0.016196399927139282,\n",
       "  0.023996107280254364,\n",
       "  0.033820364624261856,\n",
       "  0.013315308839082718,\n",
       "  -0.008351268246769905,\n",
       "  -0.0016490024281665683,\n",
       "  -0.0036824746057391167,\n",
       "  0.008669226430356503,\n",
       "  0.004665549378842115,\n",
       "  -0.00846806913614273,\n",
       "  0.0025712433271110058,\n",
       "  0.0013480776688084006,\n",
       "  -0.025267940014600754,\n",
       "  0.026228303089737892,\n",
       "  -0.010888444259762764,\n",
       "  0.0026653329841792583,\n",
       "  0.02756502479314804,\n",
       "  0.02920023910701275,\n",
       "  -0.026916131377220154,\n",
       "  0.00689125619828701,\n",
       "  0.019726384431123734,\n",
       "  0.009798302315175533,\n",
       "  0.0041561671532690525,\n",
       "  0.01918131299316883,\n",
       "  0.02524198405444622,\n",
       "  0.006323473993688822,\n",
       "  0.011180447414517403,\n",
       "  -0.0015808684984222054,\n",
       "  0.005960093345493078,\n",
       "  0.01849348470568657,\n",
       "  -0.004811550490558147,\n",
       "  -0.016832316294312477,\n",
       "  0.004798572510480881,\n",
       "  0.009123452007770538,\n",
       "  0.01828583888709545,\n",
       "  0.004415724892169237,\n",
       "  0.01841561682522297,\n",
       "  0.015158168040215969,\n",
       "  -0.023801438510417938,\n",
       "  0.018597308546304703,\n",
       "  0.0008881739340722561,\n",
       "  -0.005084086209535599,\n",
       "  0.0021754177287220955,\n",
       "  0.00823446735739708,\n",
       "  0.0009782080305740237,\n",
       "  -0.00529822101816535,\n",
       "  -0.0025971990544348955,\n",
       "  0.026786351576447487,\n",
       "  -0.016819337382912636,\n",
       "  0.031717948615550995,\n",
       "  0.013055751100182533,\n",
       "  -0.0008751960704103112,\n",
       "  0.0016084464732557535,\n",
       "  0.0005284431972540915,\n",
       "  -0.010122749954462051,\n",
       "  -0.020842481404542923,\n",
       "  -0.03480668365955353,\n",
       "  0.015599416568875313,\n",
       "  0.010505597107112408,\n",
       "  -0.004704482853412628,\n",
       "  -0.023554859682917595,\n",
       "  -0.03916725516319275,\n",
       "  0.008935272693634033,\n",
       "  0.009052074514329433,\n",
       "  0.006119072437286377,\n",
       "  -0.004779105540364981,\n",
       "  0.022815119475126266,\n",
       "  0.030316336080431938,\n",
       "  -0.02246471680700779,\n",
       "  0.0020699724555015564,\n",
       "  0.0020245499908924103,\n",
       "  0.03929703310132027,\n",
       "  -0.0077218408696353436,\n",
       "  0.0012004543095827103,\n",
       "  0.007780241314321756,\n",
       "  0.000997674884274602,\n",
       "  0.004178878851234913,\n",
       "  0.005486400332301855,\n",
       "  -0.005307954736053944,\n",
       "  -0.005973071325570345,\n",
       "  0.017507165670394897,\n",
       "  -0.008299357257783413,\n",
       "  -0.021153951063752174,\n",
       "  -0.007397393696010113,\n",
       "  0.016365110874176025,\n",
       "  -0.0041756341233849525,\n",
       "  0.03275617957115173,\n",
       "  -0.009493322111666203,\n",
       "  0.01523603592067957,\n",
       "  0.0005134375533089042,\n",
       "  0.007689396385103464,\n",
       "  -0.009259720332920551,\n",
       "  -0.002154328627511859,\n",
       "  0.02007678709924221,\n",
       "  -0.010551019571721554,\n",
       "  -0.02547558583319187,\n",
       "  -0.008584870025515556,\n",
       "  -0.018337750807404518,\n",
       "  -0.0015338236698880792,\n",
       "  0.054039910435676575,\n",
       "  0.022049425169825554,\n",
       "  -0.006132049951702356,\n",
       "  0.0018055480904877186,\n",
       "  0.010875467211008072,\n",
       "  0.01931109093129635,\n",
       "  -0.00021352674230001867,\n",
       "  -0.014223760925233364,\n",
       "  -0.013276374898850918,\n",
       "  -0.014392473734915257,\n",
       "  0.010213594883680344,\n",
       "  -0.017429297789931297,\n",
       "  -0.01358784455806017,\n",
       "  0.003721408313140273,\n",
       "  0.004526037257164717,\n",
       "  0.001683880458585918,\n",
       "  0.02023252099752426,\n",
       "  -0.006806900259107351,\n",
       "  0.01258854754269123,\n",
       "  -0.0029021792579442263,\n",
       "  -0.006355918478220701,\n",
       "  0.0028843346517533064,\n",
       "  0.011589250527322292,\n",
       "  0.025813011452555656,\n",
       "  0.015365814790129662,\n",
       "  0.012011031620204449,\n",
       "  0.022802142426371574,\n",
       "  0.018921755254268646,\n",
       "  0.010213594883680344,\n",
       "  -0.026020657271146774,\n",
       "  -0.008526469580829144,\n",
       "  -0.0023554859217256308,\n",
       "  0.013613800518214703,\n",
       "  0.006352674216032028,\n",
       "  -0.0011469204910099506,\n",
       "  0.02772076055407524,\n",
       "  -0.010966312140226364,\n",
       "  0.010518575087189674,\n",
       "  0.022503651678562164,\n",
       "  -0.012218677438795567,\n",
       "  0.006800411269068718,\n",
       "  0.016949117183685303,\n",
       "  0.00535337720066309,\n",
       "  -0.01701400615274906,\n",
       "  0.018091170117259026,\n",
       "  -0.01938895881175995,\n",
       "  -0.019648516550660133,\n",
       "  0.0323408879339695,\n",
       "  -0.009791813790798187,\n",
       "  -0.009188341908156872,\n",
       "  0.028499433770775795,\n",
       "  0.000983074656687677,\n",
       "  -0.01610555313527584,\n",
       "  -0.010505597107112408,\n",
       "  -0.001756881014443934,\n",
       "  0.006024982780218124,\n",
       "  -0.02015465311706066,\n",
       "  -0.011316714808344841,\n",
       "  -0.009136429987847805,\n",
       "  0.007663440424948931,\n",
       "  -0.010862489230930805,\n",
       "  -0.02014167606830597,\n",
       "  0.007728329859673977,\n",
       "  -0.00649867532774806,\n",
       "  -0.028369653970003128,\n",
       "  -0.03192559629678726,\n",
       "  -0.027616936713457108,\n",
       "  -0.011809874325990677,\n",
       "  -0.015677284449338913,\n",
       "  0.00368896359577775,\n",
       "  -0.016144488006830215,\n",
       "  -0.0013383443001657724,\n",
       "  -0.01194614265114069,\n",
       "  -0.005603201221674681,\n",
       "  0.001844481797888875,\n",
       "  0.01737738586962223,\n",
       "  0.004860217683017254,\n",
       "  -0.013756557367742062,\n",
       "  0.024437354877591133,\n",
       "  0.007066457998007536,\n",
       "  -0.012264099903404713,\n",
       "  -0.03054993972182274,\n",
       "  0.002128372900187969,\n",
       "  -0.01835072785615921,\n",
       "  0.0131076630204916,\n",
       "  0.009869680739939213,\n",
       "  -0.009597145020961761,\n",
       "  -0.0048861731775105,\n",
       "  -0.008734116330742836,\n",
       "  0.0008297734311781824,\n",
       "  0.02560536563396454,\n",
       "  0.01100524514913559,\n",
       "  0.01094035618007183,\n",
       "  -0.008623803965747356,\n",
       "  0.0027350890450179577,\n",
       "  -0.012893527746200562,\n",
       "  0.01918131299316883,\n",
       "  0.0002557048574090004,\n",
       "  -0.01111555751413107,\n",
       "  -0.015002434141933918,\n",
       "  0.003945276606827974,\n",
       "  0.0028210675809532404,\n",
       "  -0.0028843346517533064,\n",
       "  -0.010946844704449177,\n",
       "  0.01588493026793003,\n",
       "  0.0017731033731251955,\n",
       "  0.011660628952085972,\n",
       "  0.009110474959015846,\n",
       "  -0.018454551696777344,\n",
       "  -0.011465960182249546,\n",
       "  0.033508896827697754,\n",
       "  -0.010518575087189674,\n",
       "  0.010810577310621738,\n",
       "  -0.0005235765129327774,\n",
       "  -0.0014462228864431381,\n",
       "  0.017169740051031113,\n",
       "  0.003883631667122245,\n",
       "  0.026384038850665092,\n",
       "  0.0004874817677773535,\n",
       "  -0.03519602119922638,\n",
       "  0.008305845782160759,\n",
       "  -0.0395565889775753,\n",
       "  0.03010869026184082,\n",
       "  -0.004208079073578119,\n",
       "  0.007676418405026197,\n",
       "  0.0033109826035797596,\n",
       "  0.014431406743824482,\n",
       "  -0.01074568834155798,\n",
       "  -0.003491050796583295,\n",
       "  0.001743903150781989,\n",
       "  -0.007215703371912241,\n",
       "  0.021102039143443108,\n",
       "  0.008967718109488487,\n",
       "  -0.015703240409493446,\n",
       "  -0.025800032541155815,\n",
       "  -0.01415887102484703,\n",
       "  -0.02712377719581127,\n",
       "  0.011699561960995197,\n",
       "  -0.00018027091573458165,\n",
       "  -0.027513114735484123,\n",
       "  -0.021011194214224815,\n",
       "  -0.01134915929287672,\n",
       "  0.002897312631830573,\n",
       "  -0.014171849004924297,\n",
       "  -0.023464014753699303,\n",
       "  -0.04360568895936012,\n",
       "  -0.011985075660049915,\n",
       "  0.009817768819630146,\n",
       "  -0.010233061388134956,\n",
       "  0.010382306762039661,\n",
       "  -0.00526253180578351,\n",
       "  0.0025469097308814526,\n",
       "  -0.02417779713869095,\n",
       "  -0.04046504199504852,\n",
       "  -0.007981399074196815,\n",
       "  -0.02689017541706562,\n",
       "  -0.01633915677666664,\n",
       "  0.0014008003054186702,\n",
       "  0.03402801230549812,\n",
       "  0.021699022501707077,\n",
       "  0.01850646175444126,\n",
       "  0.0014665009221062064,\n",
       "  0.0029865356627851725,\n",
       "  0.0008261234033852816,\n",
       "  0.017701834440231323,\n",
       "  0.016378089785575867,\n",
       "  -0.007916509173810482,\n",
       "  0.010758665390312672,\n",
       "  -0.017416320741176605,\n",
       "  0.022581517696380615,\n",
       "  0.03286000341176987,\n",
       "  0.020258476957678795,\n",
       "  0.0037311415653675795,\n",
       "  0.009603634476661682,\n",
       "  0.02201049029827118,\n",
       "  0.018311794847249985,\n",
       "  0.00246093119494617,\n",
       "  -0.012536635622382164,\n",
       "  -0.009480344131588936,\n",
       "  -0.036364030092954636,\n",
       "  -0.006145027931779623,\n",
       "  -0.010985778644680977,\n",
       "  -0.01149191614240408,\n",
       "  0.008189044892787933,\n",
       "  0.008299357257783413,\n",
       "  -0.009551722556352615,\n",
       "  0.0328080914914608,\n",
       "  0.01947980374097824,\n",
       "  0.037246525287628174,\n",
       "  0.00946736615151167,\n",
       "  0.021776888519525528,\n",
       "  0.004577948711812496,\n",
       "  0.028629211708903313,\n",
       "  0.016053643077611923,\n",
       "  0.016053643077611923,\n",
       "  0.016196399927139282,\n",
       "  -0.004182123113423586,\n",
       "  -0.008007354103028774,\n",
       "  -0.009564700536429882,\n",
       "  0.020349321886897087,\n",
       "  -0.0037149193231016397,\n",
       "  0.007624506950378418,\n",
       "  -0.020284432917833328,\n",
       "  0.009408965706825256,\n",
       "  -0.011783918365836143,\n",
       "  0.015742173418402672,\n",
       "  -0.006531120277941227,\n",
       "  -0.019505759701132774,\n",
       "  -0.015158168040215969,\n",
       "  -0.006232628598809242,\n",
       "  -0.01685827039182186,\n",
       "  -0.014574163593351841,\n",
       "  -0.001784458989277482,\n",
       "  -0.021984536200761795,\n",
       "  0.010778132826089859,\n",
       "  -0.01105066854506731,\n",
       "  -0.010719732381403446,\n",
       "  0.01766289956867695,\n",
       "  -0.018817931413650513,\n",
       "  -0.026176391169428825,\n",
       "  0.0015038122655823827,\n",
       "  -0.013256908394396305,\n",
       "  0.027824582532048225,\n",
       "  0.0003463472821749747,\n",
       "  0.014885633252561092,\n",
       "  0.01344508770853281,\n",
       "  -0.025813011452555656,\n",
       "  -0.020712703466415405,\n",
       "  -0.005732980091124773,\n",
       "  0.007351971231400967,\n",
       "  -0.003711674828082323,\n",
       "  0.018830910325050354,\n",
       "  -0.002933001844212413,\n",
       "  -0.0057848915457725525,\n",
       "  -0.021608177572488785,\n",
       "  0.008260423317551613,\n",
       "  -0.002420375356450677,\n",
       "  0.005035419017076492,\n",
       "  -0.015768129378557205,\n",
       "  0.013717623427510262,\n",
       "  0.018454551696777344,\n",
       "  -0.005294976755976677,\n",
       "  -0.020699724555015564,\n",
       "  -0.008448602631688118,\n",
       "  -0.02389228530228138,\n",
       "  0.008312334306538105,\n",
       "  0.007280592806637287,\n",
       "  0.004454658832401037,\n",
       "  -0.009162385948002338,\n",
       "  -0.009551722556352615,\n",
       "  -0.003802519990131259,\n",
       "  0.02637105993926525,\n",
       "  -0.026838263496756554,\n",
       "  0.017130807042121887,\n",
       "  0.021296707913279533,\n",
       "  -0.015923863276839256,\n",
       "  -0.011414049193263054,\n",
       "  0.007864597253501415,\n",
       "  -0.015352836810052395,\n",
       "  0.025553453713655472,\n",
       "  0.0020115720108151436,\n",
       "  0.017559077590703964,\n",
       "  -0.022347915917634964,\n",
       "  0.023619748651981354,\n",
       "  0.01579408533871174,\n",
       "  0.002525820629671216,\n",
       "  -0.020946305245161057,\n",
       "  -0.00017804033996071666,\n",
       "  -0.0011469204910099506,\n",
       "  0.029771266505122185,\n",
       "  -0.007566106505692005,\n",
       "  0.004483859054744244,\n",
       "  0.0006651165313087404,\n",
       "  0.011057157069444656,\n",
       "  0.010421240702271461,\n",
       "  -0.0018493484240025282,\n",
       "  -0.013328286819159985,\n",
       "  -0.022140270099043846,\n",
       "  -0.020466122776269913,\n",
       "  -0.0024966204073280096,\n",
       "  0.04241172596812248,\n",
       "  0.012108366005122662,\n",
       "  -0.019285134971141815,\n",
       "  -0.01344508770853281,\n",
       "  -0.021893689408898354,\n",
       "  -0.01932406984269619,\n",
       "  -0.03174390271306038,\n",
       "  0.006037960294634104,\n",
       "  0.0015411237254738808,\n",
       "  0.0018428595503792167,\n",
       "  -0.018675174564123154,\n",
       "  -0.02247769571840763,\n",
       "  0.0009392743231728673,\n",
       "  0.013730601407587528,\n",
       "  0.01587195135653019,\n",
       "  -0.008494025096297264,\n",
       "  -0.006858811713755131,\n",
       "  0.019337046891450882,\n",
       "  -0.02133564092218876,\n",
       "  0.009597145020961761,\n",
       "  -0.00485048396512866,\n",
       "  -0.0011947763850912452,\n",
       "  -0.04303466156125069,\n",
       "  0.019285134971141815,\n",
       "  -0.009408965706825256,\n",
       "  -0.015547504648566246,\n",
       "  0.009447899647057056,\n",
       "  -0.008403180167078972,\n",
       "  -0.03529984503984451,\n",
       "  -0.002287351991981268,\n",
       "  0.014444384723901749,\n",
       "  0.017585033550858498,\n",
       "  0.02193262428045273,\n",
       "  -0.00842913519591093,\n",
       "  0.023269345983862877,\n",
       "  0.008442113175988197,\n",
       "  -0.010129238478839397,\n",
       "  -0.0056583574041724205,\n",
       "  -0.025203051045536995,\n",
       "  0.006446763873100281,\n",
       "  -0.023476991802453995,\n",
       "  -0.002814578590914607,\n",
       "  -0.010888444259762764,\n",
       "  0.001679013716056943,\n",
       "  0.02717568911612034,\n",
       "  -0.014042070135474205,\n",
       "  0.019869139418005943,\n",
       "  -0.0038317202124744654,\n",
       "  -0.020323365926742554,\n",
       "  -0.019142378121614456,\n",
       "  -0.005625912919640541,\n",
       "  0.026409992948174477,\n",
       "  -0.014703942462801933,\n",
       "  0.024164820089936256,\n",
       "  0.001468934235163033,\n",
       "  -0.0106353759765625,\n",
       "  -0.016598714515566826,\n",
       "  0.008935272693634033,\n",
       "  0.0030222246423363686,\n",
       "  -0.00691072316840291,\n",
       "  0.0163261778652668,\n",
       "  0.006995079573243856,\n",
       "  -0.010453685186803341,\n",
       "  0.004337857943028212,\n",
       "  -0.005408532917499542,\n",
       "  -0.012614503502845764,\n",
       "  0.0034066946245729923,\n",
       "  -0.027746716514229774,\n",
       "  -0.010174660943448544,\n",
       "  0.006742010824382305,\n",
       "  -0.007098902482539415,\n",
       "  0.016040664166212082,\n",
       "  0.022503651678562164,\n",
       "  -0.030238470062613487,\n",
       "  -0.017559077590703964,\n",
       "  0.0021121506579220295,\n",
       "  -0.026760397478938103,\n",
       "  -0.007871086709201336,\n",
       "  -0.00013515249884221703,\n",
       "  0.013393175788223743,\n",
       "  0.027954362332820892,\n",
       "  0.009240253828465939,\n",
       "  -0.0021478398703038692,\n",
       "  0.014055048115551472,\n",
       "  0.003119558794423938,\n",
       "  0.014016115106642246,\n",
       "  -0.005632401444017887,\n",
       "  -0.010207105427980423,\n",
       "  0.005158708896487951,\n",
       "  -0.004425458610057831,\n",
       "  0.017117828130722046,\n",
       "  0.0024885092861950397,\n",
       "  -0.0357930026948452,\n",
       "  -0.025436652824282646,\n",
       "  0.01693613827228546,\n",
       "  -0.0017714811256155372,\n",
       "  -0.016287244856357574,\n",
       "  0.02006380818784237,\n",
       "  -0.0057848915457725525,\n",
       "  -0.008591359481215477,\n",
       "  -0.01519710198044777,\n",
       "  0.006349429953843355,\n",
       "  -0.00861082598567009,\n",
       "  -0.0018315038178116083,\n",
       "  0.011855296790599823,\n",
       "  -0.007708862889558077,\n",
       "  -3.067039142479189e-05,\n",
       "  0.019817229360342026,\n",
       "  -0.025592386722564697,\n",
       "  0.0020391501020640135,\n",
       "  -0.006505164317786694,\n",
       "  -0.003126047784462571,\n",
       "  -0.001990482909604907,\n",
       "  0.0006172605790197849,\n",
       "  -0.018480507656931877,\n",
       "  -0.004788839258253574,\n",
       "  0.015249013900756836,\n",
       "  -0.024294598028063774,\n",
       "  0.016352133825421333,\n",
       "  0.004636349156498909,\n",
       "  -0.021737955510616302,\n",
       "  0.03960850089788437,\n",
       "  -0.010739198885858059,\n",
       "  -0.00041346726357005537,\n",
       "  -0.021673066541552544,\n",
       "  0.003812253475189209,\n",
       "  -0.010466663166880608,\n",
       "  -0.011141513474285603,\n",
       "  0.022957876324653625,\n",
       "  -0.0011104202130809426,\n",
       "  -0.011362137272953987,\n",
       "  -0.019427891820669174,\n",
       "  -0.007124858442693949,\n",
       "  -0.029537664726376534,\n",
       "  -0.0025696209631860256,\n",
       "  -0.03345698490738869,\n",
       "  -0.005509111564606428,\n",
       "  -0.014548207633197308,\n",
       "  0.026993999257683754,\n",
       "  -0.006839344743639231,\n",
       "  -0.003546206746250391,\n",
       "  -0.0021202617790549994,\n",
       "  -0.01015519443899393,\n",
       "  -0.014444384723901749,\n",
       "  -0.00781917478889227,\n",
       "  -0.008481047116219997,\n",
       "  0.01850646175444126,\n",
       "  0.012608014047145844,\n",
       "  -0.004824528470635414,\n",
       "  -0.004694749601185322,\n",
       "  -0.004091277718544006,\n",
       "  -0.028888769447803497,\n",
       "  -0.005583734717220068,\n",
       "  0.01828583888709545,\n",
       "  -0.0014624452451243997,\n",
       "  0.024073975160717964,\n",
       "  0.2023511677980423,\n",
       "  3.7615584005834535e-05,\n",
       "  -0.003015735885128379,\n",
       "  0.041814740747213364,\n",
       "  0.00700156856328249,\n",
       "  0.0032655601389706135,\n",
       "  0.015988752245903015,\n",
       "  0.02120586298406124,\n",
       "  -0.02097226120531559,\n",
       "  0.019752338528633118,\n",
       "  -0.019895095378160477,\n",
       "  0.013432109728455544,\n",
       "  -0.021283729001879692,\n",
       "  0.0012077543651685119,\n",
       "  0.014976478181779385,\n",
       "  -0.005771914031356573,\n",
       "  -0.03122478909790516,\n",
       "  -0.008117666468024254,\n",
       "  -0.03519602119922638,\n",
       "  -0.012828637845814228,\n",
       "  -0.012134321965277195,\n",
       "  -0.002681555226445198,\n",
       "  -0.017546098679304123,\n",
       "  -0.0020277942530810833,\n",
       "  0.036208298057317734,\n",
       "  0.01382144633680582,\n",
       "  0.003028713632375002,\n",
       "  0.006806900259107351,\n",
       "  0.018065214157104492,\n",
       "  0.006904234178364277,\n",
       "  -0.012166766449809074,\n",
       "  -0.034650951623916626,\n",
       "  0.013899313285946846,\n",
       "  0.012711836956441402,\n",
       "  -0.0010009192628785968,\n",
       "  -0.007961931638419628,\n",
       "  -0.007643973454833031,\n",
       "  0.0017406586557626724,\n",
       "  0.017247607931494713,\n",
       "  -0.003020602511242032,\n",
       "  -0.0019304602174088359,\n",
       "  0.01265992596745491,\n",
       "  0.015482615679502487,\n",
       "  -0.01519710198044777,\n",
       "  -0.01676742546260357,\n",
       "  0.007488239090889692,\n",
       "  ...],\n",
       " {'text': 'hi',\n",
       "  'date_uploaded': datetime.datetime(2024, 3, 7, 5, 21, 30, 373678)})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_for_pinecone(texts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1b73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:   49f68a5c8493ec2c0bf489821c21fc3b \n",
      "LEN:  1536 \n",
      "META: {'text': 'hi', 'date_uploaded': datetime.datetime(2024, 3, 7, 5, 21, 30, 973413)}\n"
     ]
    }
   ],
   "source": [
    "_id, embedding, metadata = prepare_for_pinecone(texts)[0]\n",
    "\n",
    "print('ID:  ',_id, '\\nLEN: ', len(embedding), '\\nMETA:', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49debd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf47aabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_texts_to_pinecone(texts, namespace=NAMESPACE, batch_size=None, show_progress_bar=False):\n",
    "    # prepare_for_pinecone 함수를 호출하여 인덱싱을 위해 입력 텍스트를 준비합니다.\n",
    "    total_upserted = 0\n",
    "    if not batch_size:\n",
    "        batch_size = len(texts)\n",
    "\n",
    "    _range = range(0, len(texts), batch_size)\n",
    "    for i in tqdm(_range) if show_progress_bar else _range:\n",
    "        batch = texts[i: i + batch_size]\n",
    "        prepared_texts = prepare_for_pinecone(batch)\n",
    "\n",
    "        # 인덱스 객체의 upsert() 메서드를 사용하여 준비된 텍스트를 Pinecone에 업로드합니다.\n",
    "        total_upserted += index.upsert(\n",
    "            prepared_texts,\n",
    "            namespace=namespace\n",
    "        )['upserted_count']\n",
    "\n",
    "    return total_upserted\n",
    "\n",
    "# 입력 텍스트로 upload_texts_to_pinecone() 함수를 호출합니다.\n",
    "upload_texts_to_pinecone(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8ed7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_from_pinecone(query, top_k=3):\n",
    "    # 문서와 동일한 임베더에서 임베딩 받기\n",
    "    query_embedding = get_embedding(query, engine=ENGINE)\n",
    "    # query_embedding = get_embedding(query)\n",
    "\n",
    "    return index.query(\n",
    "      vector=query_embedding,\n",
    "      top_k=top_k,\n",
    "      namespace=NAMESPACE,\n",
    "      include_metadata=True   # gets the metadata (dates, text, etc)\n",
    "    ).get('matches')\n",
    "\n",
    "query_from_pinecone('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a0871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def delete_texts_from_pinecone(texts, namespace=NAMESPACE):\n",
    "    # 각 텍스트의 해시(ID)를 계산합니다.\n",
    "    hashes = [hashlib.md5(text.encode()).hexdigest() for text in texts]\n",
    "    \n",
    "    # ids 매개변수는 삭제할 ID(해시) 목록을 지정하는 데 사용됩니다.\n",
    "    return index.delete(ids=hashes, namespace=namespace)\n",
    "\n",
    "# 텍스트 삭제\n",
    "delete_texts_from_pinecone(texts)\n",
    "\n",
    "# 인덱스가 비어 있는지 테스트\n",
    "query_from_pinecone('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bac4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72729603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36661, 1070]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 틱토큰 라이브러리 가져오기\n",
    "import tiktoken\n",
    "\n",
    "# 'cl100k_base' 모델에 대한 토큰화 도구 초기화하기\n",
    "# 이 토큰화 도구는 'ada-002' 임베딩 모델과 함께 작동하도록 설계되었습니다.\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# 토큰라이저를 사용하여 'hey there' 텍스트를 인코딩하기\n",
    "# 결과 출력은 인코딩된 텍스트를 나타내는 정수 목록입니다.\n",
    "# 'ada-002' 모델을 사용하여 임베딩하는 데 필요한 입력 형식입니다.\n",
    "tokenizer.encode('hey there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc147d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84f34d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 최대 토큰 수의 청크로 분할하는 함수입니다. OpenAI에서 영감을 얻음\n",
    "def overlapping_chunks(text, max_tokens = 500, overlapping_factor = 5):\n",
    "    '''\n",
    "    max_tokens: 청크당 원하는 토큰 수\n",
    "    overlapping_factor: 이전 청크와 겹치는 각 청크를 시작할 문장 수\n",
    "    '''\n",
    "\n",
    "    # 문장 부호를 사용하여 텍스트 분할\n",
    "    sentences = re.split(r'[.?!]', text)\n",
    "\n",
    "    # 각 문장의 토큰 개수 가져오기\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks, tokens_so_far, chunk = [], 0, []\n",
    "\n",
    "    # 튜플로 결합된 문장과 토큰을 반복합니다.\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # 지금까지의 토큰 수에 현재 문장의 토큰 수를 더한 수가 \n",
    "        # 최대 토큰 수보다 크면 청크 목록에 청크를 추가하고 재설정합니다.\n",
    "        # 청크와 지금까지의 토큰을 재설정합니다.\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            if overlapping_factor > 0:\n",
    "                chunk = chunk[-overlapping_factor:]\n",
    "                tokens_so_far = sum([len(tokenizer.encode(c)) for c in chunk])\n",
    "            else:\n",
    "                chunk = []\n",
    "                tokens_so_far = 0\n",
    "\n",
    "        # 현재 문장의 토큰 수가 최대 토큰 수보다 많으면 \n",
    "        # 토큰 수보다 많으면 다음 문장으로 이동합니다.\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # 그렇지 않으면, 청크에 문장을 추가하고 토큰 수를 합산합니다.\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk) + \".\")\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3164e0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 428/428 [04:55<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# 읽기 바이너리 모드로 PDF 파일 열기\n",
    "with open(BASE_DIR + '../data/pds2.pdf', 'rb') as file:\n",
    "\n",
    "    # PDF 리더 객체를 만듭니다.\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "    # 텍스트를 담을 빈 문자열을 초기화합니다.\n",
    "    principles_of_ds = ''\n",
    "    # PDF 파일의 각 페이지를 반복합니다.\n",
    "    for page in tqdm(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        principles_of_ds += '\\n\\n' + text[text.find(' ]')+2:]\n",
    "\n",
    "# PDF 파일의 모든 텍스트가 포함된 최종 문자열을 인쇄합니다.\n",
    "principles_of_ds = principles_of_ds.strip()\n",
    "\n",
    "print(len(principles_of_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43e01a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# 곤충에 관한 교과서\n",
    "text = urlopen('https://www.gutenberg.org/cache/epub/10834/pg10834.txt').read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfdac6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-overlapping chunking approach has 286 documents with average length 474.1 tokens\n"
     ]
    }
   ],
   "source": [
    "split = overlapping_chunks(principles_of_ds, overlapping_factor=0)\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in split]) / len(split)\n",
    "print(f'non-overlapping chunking approach has {len(split)} documents with average length {avg_length:.1f} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1730b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping chunking approach has 392 documents with average length 485.2 tokens\n"
     ]
    }
   ],
   "source": [
    "split = overlapping_chunks(principles_of_ds)\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in split]) / len(split)\n",
    "print(f'overlapping chunking approach has {len(split)} documents with average length {avg_length:.1f} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1381cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fc7dc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 82259), ('\\n', 9220), ('  ', 1592), ('\\n\\n', 333), ('\\n   ', 250), ('\\n\\n\\n', 82), ('\\n    ', 73), ('\\n ', 46), (' \\n', 39), ('     ', 34)]\n"
     ]
    }
   ],
   "source": [
    "# 카운터 및 re 라이브러리 가져오기\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# 'principles_of_ds'에서 하나 이상의 공백이 있는 모든 항목 찾기\n",
    "matches = re.findall(r'[\\s]{1,}', principles_of_ds)\n",
    "\n",
    "# 문서에서 가장 빈번하게 발생하는 공백 10가지\n",
    "most_common_spaces = Counter(matches).most_common(10)\n",
    "\n",
    "# 가장 일반적인 공백과 그 빈도를 인쇄합니다.\n",
    "print(most_common_spaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63ccc253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom delimiter approach has 426 documents with average length 316.3 tokens\n"
     ]
    }
   ],
   "source": [
    "# Only keep documents of at least 100 characters split by a custom delimiter\n",
    "split = list(filter(lambda x: len(x) > 50, principles_of_ds.split('\\n\\n')))\n",
    "\n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in split]) / len(split)\n",
    "print(f'custom delimiter approach has {len(split)} documents with average length {avg_length:.1f} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2480fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = None\n",
    "for s in tqdm(range(0, len(split), 100)):\n",
    "    if embeddings is None:\n",
    "        embeddings = np.array(get_embeddings(split[s:s+100], engine=ENGINE))\n",
    "    else:\n",
    "        embeddings = np.vstack([embeddings, np.array(get_embeddings(split[s:s+100], engine=ENGINE))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cfe8fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 1 embeddings\n",
      "Cluster 1: 1 embeddings\n",
      "Cluster 2: 1 embeddings\n",
      "Cluster 3: 1 embeddings\n",
      "Cluster 4: 1 embeddings\n",
      "Cluster 5: 1 embeddings\n",
      "Cluster 6: 1 embeddings\n",
      "Cluster 7: 1 embeddings\n",
      "Cluster 8: 1 embeddings\n",
      "Cluster 9: 1 embeddings\n",
      "Cluster 10: 1 embeddings\n",
      "Cluster 11: 1 embeddings\n",
      "Cluster 12: 1 embeddings\n",
      "Cluster 13: 1 embeddings\n",
      "Cluster 14: 1 embeddings\n",
      "Cluster 15: 1 embeddings\n",
      "Cluster 16: 1 embeddings\n",
      "Cluster 17: 1 embeddings\n",
      "Cluster 18: 1 embeddings\n",
      "Cluster 19: 1 embeddings\n",
      "Cluster 20: 1 embeddings\n",
      "Cluster 21: 1 embeddings\n",
      "Cluster 22: 1 embeddings\n",
      "Cluster 23: 1 embeddings\n",
      "Cluster 24: 1 embeddings\n",
      "Cluster 25: 1 embeddings\n",
      "Cluster 26: 1 embeddings\n",
      "Cluster 27: 1 embeddings\n",
      "Cluster 28: 1 embeddings\n",
      "Cluster 29: 1 embeddings\n",
      "Cluster 30: 1 embeddings\n",
      "Cluster 31: 1 embeddings\n",
      "Cluster 32: 1 embeddings\n",
      "Cluster 33: 1 embeddings\n",
      "Cluster 34: 1 embeddings\n",
      "Cluster 35: 1 embeddings\n",
      "Cluster 36: 1 embeddings\n",
      "Cluster 37: 1 embeddings\n",
      "Cluster 38: 1 embeddings\n",
      "Cluster 39: 1 embeddings\n",
      "Cluster 40: 1 embeddings\n",
      "Cluster 41: 1 embeddings\n",
      "Cluster 42: 1 embeddings\n",
      "Cluster 43: 1 embeddings\n",
      "Cluster 44: 1 embeddings\n",
      "Cluster 45: 1 embeddings\n",
      "Cluster 46: 1 embeddings\n",
      "Cluster 47: 1 embeddings\n",
      "Cluster 48: 1 embeddings\n",
      "Cluster 49: 1 embeddings\n",
      "Cluster 50: 1 embeddings\n",
      "Cluster 51: 1 embeddings\n",
      "Cluster 52: 1 embeddings\n",
      "Cluster 53: 1 embeddings\n",
      "Cluster 54: 1 embeddings\n",
      "Cluster 55: 1 embeddings\n",
      "Cluster 56: 1 embeddings\n",
      "Cluster 57: 1 embeddings\n",
      "Cluster 58: 1 embeddings\n",
      "Cluster 59: 1 embeddings\n",
      "Cluster 60: 1 embeddings\n",
      "Cluster 61: 1 embeddings\n",
      "Cluster 62: 1 embeddings\n",
      "Cluster 63: 1 embeddings\n",
      "Cluster 64: 1 embeddings\n",
      "Cluster 65: 1 embeddings\n",
      "Cluster 66: 1 embeddings\n",
      "Cluster 67: 1 embeddings\n",
      "Cluster 68: 1 embeddings\n",
      "Cluster 69: 1 embeddings\n",
      "Cluster 70: 1 embeddings\n",
      "Cluster 71: 1 embeddings\n",
      "Cluster 72: 1 embeddings\n",
      "Cluster 73: 1 embeddings\n",
      "Cluster 74: 1 embeddings\n",
      "Cluster 75: 1 embeddings\n",
      "Cluster 76: 1 embeddings\n",
      "Cluster 77: 1 embeddings\n",
      "Cluster 78: 1 embeddings\n",
      "Cluster 79: 1 embeddings\n",
      "Cluster 80: 1 embeddings\n",
      "Cluster 81: 1 embeddings\n",
      "Cluster 82: 1 embeddings\n",
      "Cluster 83: 1 embeddings\n",
      "Cluster 84: 1 embeddings\n",
      "Cluster 85: 1 embeddings\n",
      "Cluster 86: 1 embeddings\n",
      "Cluster 87: 1 embeddings\n",
      "Cluster 88: 1 embeddings\n",
      "Cluster 89: 1 embeddings\n",
      "Cluster 90: 1 embeddings\n",
      "Cluster 91: 1 embeddings\n",
      "Cluster 92: 1 embeddings\n",
      "Cluster 93: 1 embeddings\n",
      "Cluster 94: 1 embeddings\n",
      "Cluster 95: 1 embeddings\n",
      "Cluster 96: 1 embeddings\n",
      "Cluster 97: 1 embeddings\n",
      "Cluster 98: 1 embeddings\n",
      "Cluster 99: 1 embeddings\n",
      "Cluster 100: 1 embeddings\n",
      "Cluster 101: 1 embeddings\n",
      "Cluster 102: 1 embeddings\n",
      "Cluster 103: 1 embeddings\n",
      "Cluster 104: 1 embeddings\n",
      "Cluster 105: 1 embeddings\n",
      "Cluster 106: 1 embeddings\n",
      "Cluster 107: 1 embeddings\n",
      "Cluster 108: 1 embeddings\n",
      "Cluster 109: 1 embeddings\n",
      "Cluster 110: 1 embeddings\n",
      "Cluster 111: 1 embeddings\n",
      "Cluster 112: 1 embeddings\n",
      "Cluster 113: 1 embeddings\n",
      "Cluster 114: 1 embeddings\n",
      "Cluster 115: 1 embeddings\n",
      "Cluster 116: 1 embeddings\n",
      "Cluster 117: 1 embeddings\n",
      "Cluster 118: 1 embeddings\n",
      "Cluster 119: 1 embeddings\n",
      "Cluster 120: 1 embeddings\n",
      "Cluster 121: 1 embeddings\n",
      "Cluster 122: 1 embeddings\n",
      "Cluster 123: 1 embeddings\n",
      "Cluster 124: 1 embeddings\n",
      "Cluster 125: 1 embeddings\n",
      "Cluster 126: 1 embeddings\n",
      "Cluster 127: 1 embeddings\n",
      "Cluster 128: 1 embeddings\n",
      "Cluster 129: 1 embeddings\n",
      "Cluster 130: 1 embeddings\n",
      "Cluster 131: 1 embeddings\n",
      "Cluster 132: 1 embeddings\n",
      "Cluster 133: 1 embeddings\n",
      "Cluster 134: 1 embeddings\n",
      "Cluster 135: 1 embeddings\n",
      "Cluster 136: 1 embeddings\n",
      "Cluster 137: 1 embeddings\n",
      "Cluster 138: 1 embeddings\n",
      "Cluster 139: 1 embeddings\n",
      "Cluster 140: 1 embeddings\n",
      "Cluster 141: 1 embeddings\n",
      "Cluster 142: 1 embeddings\n",
      "Cluster 143: 1 embeddings\n",
      "Cluster 144: 1 embeddings\n",
      "Cluster 145: 1 embeddings\n",
      "Cluster 146: 1 embeddings\n",
      "Cluster 147: 1 embeddings\n",
      "Cluster 148: 1 embeddings\n",
      "Cluster 149: 1 embeddings\n",
      "Cluster 150: 1 embeddings\n",
      "Cluster 151: 1 embeddings\n",
      "Cluster 152: 1 embeddings\n",
      "Cluster 153: 1 embeddings\n",
      "Cluster 154: 1 embeddings\n",
      "Cluster 155: 1 embeddings\n",
      "Cluster 156: 1 embeddings\n",
      "Cluster 157: 1 embeddings\n",
      "Cluster 158: 1 embeddings\n",
      "Cluster 159: 1 embeddings\n",
      "Cluster 160: 1 embeddings\n",
      "Cluster 161: 1 embeddings\n",
      "Cluster 162: 1 embeddings\n",
      "Cluster 163: 1 embeddings\n",
      "Cluster 164: 1 embeddings\n",
      "Cluster 165: 1 embeddings\n",
      "Cluster 166: 1 embeddings\n",
      "Cluster 167: 1 embeddings\n",
      "Cluster 168: 1 embeddings\n",
      "Cluster 169: 1 embeddings\n",
      "Cluster 170: 1 embeddings\n",
      "Cluster 171: 1 embeddings\n",
      "Cluster 172: 1 embeddings\n",
      "Cluster 173: 1 embeddings\n",
      "Cluster 174: 1 embeddings\n",
      "Cluster 175: 1 embeddings\n",
      "Cluster 176: 1 embeddings\n",
      "Cluster 177: 1 embeddings\n",
      "Cluster 178: 1 embeddings\n",
      "Cluster 179: 1 embeddings\n",
      "Cluster 180: 1 embeddings\n",
      "Cluster 181: 1 embeddings\n",
      "Cluster 182: 1 embeddings\n",
      "Cluster 183: 1 embeddings\n",
      "Cluster 184: 1 embeddings\n",
      "Cluster 185: 1 embeddings\n",
      "Cluster 186: 1 embeddings\n",
      "Cluster 187: 1 embeddings\n",
      "Cluster 188: 1 embeddings\n",
      "Cluster 189: 1 embeddings\n",
      "Cluster 190: 1 embeddings\n",
      "Cluster 191: 1 embeddings\n",
      "Cluster 192: 1 embeddings\n",
      "Cluster 193: 1 embeddings\n",
      "Cluster 194: 1 embeddings\n",
      "Cluster 195: 1 embeddings\n",
      "Cluster 196: 1 embeddings\n",
      "Cluster 197: 1 embeddings\n",
      "Cluster 198: 1 embeddings\n",
      "Cluster 199: 1 embeddings\n",
      "Cluster 200: 1 embeddings\n",
      "Cluster 201: 1 embeddings\n",
      "Cluster 202: 1 embeddings\n",
      "Cluster 203: 1 embeddings\n",
      "Cluster 204: 1 embeddings\n",
      "Cluster 205: 1 embeddings\n",
      "Cluster 206: 1 embeddings\n",
      "Cluster 207: 1 embeddings\n",
      "Cluster 208: 1 embeddings\n",
      "Cluster 209: 1 embeddings\n",
      "Cluster 210: 1 embeddings\n",
      "Cluster 211: 1 embeddings\n",
      "Cluster 212: 1 embeddings\n",
      "Cluster 213: 1 embeddings\n",
      "Cluster 214: 1 embeddings\n",
      "Cluster 215: 1 embeddings\n",
      "Cluster 216: 1 embeddings\n",
      "Cluster 217: 1 embeddings\n",
      "Cluster 218: 1 embeddings\n",
      "Cluster 219: 1 embeddings\n",
      "Cluster 220: 1 embeddings\n",
      "Cluster 221: 1 embeddings\n",
      "Cluster 222: 1 embeddings\n",
      "Cluster 223: 1 embeddings\n",
      "Cluster 224: 1 embeddings\n",
      "Cluster 225: 1 embeddings\n",
      "Cluster 226: 1 embeddings\n",
      "Cluster 227: 1 embeddings\n",
      "Cluster 228: 1 embeddings\n",
      "Cluster 229: 1 embeddings\n",
      "Cluster 230: 1 embeddings\n",
      "Cluster 231: 1 embeddings\n",
      "Cluster 232: 1 embeddings\n",
      "Cluster 233: 1 embeddings\n",
      "Cluster 234: 1 embeddings\n",
      "Cluster 235: 1 embeddings\n",
      "Cluster 236: 1 embeddings\n",
      "Cluster 237: 1 embeddings\n",
      "Cluster 238: 1 embeddings\n",
      "Cluster 239: 1 embeddings\n",
      "Cluster 240: 1 embeddings\n",
      "Cluster 241: 1 embeddings\n",
      "Cluster 242: 1 embeddings\n",
      "Cluster 243: 1 embeddings\n",
      "Cluster 244: 1 embeddings\n",
      "Cluster 245: 1 embeddings\n",
      "Cluster 246: 1 embeddings\n",
      "Cluster 247: 1 embeddings\n",
      "Cluster 248: 1 embeddings\n",
      "Cluster 249: 1 embeddings\n",
      "Cluster 250: 1 embeddings\n",
      "Cluster 251: 1 embeddings\n",
      "Cluster 252: 1 embeddings\n",
      "Cluster 253: 1 embeddings\n",
      "Cluster 254: 1 embeddings\n",
      "Cluster 255: 1 embeddings\n",
      "Cluster 256: 1 embeddings\n",
      "Cluster 257: 1 embeddings\n",
      "Cluster 258: 1 embeddings\n",
      "Cluster 259: 1 embeddings\n",
      "Cluster 260: 1 embeddings\n",
      "Cluster 261: 1 embeddings\n",
      "Cluster 262: 1 embeddings\n",
      "Cluster 263: 1 embeddings\n",
      "Cluster 264: 1 embeddings\n",
      "Cluster 265: 1 embeddings\n",
      "Cluster 266: 1 embeddings\n",
      "Cluster 267: 1 embeddings\n",
      "Cluster 268: 1 embeddings\n",
      "Cluster 269: 1 embeddings\n",
      "Cluster 270: 1 embeddings\n",
      "Cluster 271: 1 embeddings\n",
      "Cluster 272: 1 embeddings\n",
      "Cluster 273: 1 embeddings\n",
      "Cluster 274: 1 embeddings\n",
      "Cluster 275: 1 embeddings\n",
      "Cluster 276: 1 embeddings\n",
      "Cluster 277: 1 embeddings\n",
      "Cluster 278: 1 embeddings\n",
      "Cluster 279: 1 embeddings\n",
      "Cluster 280: 1 embeddings\n",
      "Cluster 281: 1 embeddings\n",
      "Cluster 282: 1 embeddings\n",
      "Cluster 283: 1 embeddings\n",
      "Cluster 284: 1 embeddings\n",
      "Cluster 285: 1 embeddings\n",
      "Cluster 286: 1 embeddings\n",
      "Cluster 287: 1 embeddings\n",
      "Cluster 288: 1 embeddings\n",
      "Cluster 289: 1 embeddings\n",
      "Cluster 290: 1 embeddings\n",
      "Cluster 291: 1 embeddings\n",
      "Cluster 292: 1 embeddings\n",
      "Cluster 293: 1 embeddings\n",
      "Cluster 294: 1 embeddings\n",
      "Cluster 295: 1 embeddings\n",
      "Cluster 296: 1 embeddings\n",
      "Cluster 297: 1 embeddings\n",
      "Cluster 298: 1 embeddings\n",
      "Cluster 299: 1 embeddings\n",
      "Cluster 300: 1 embeddings\n",
      "Cluster 301: 1 embeddings\n",
      "Cluster 302: 1 embeddings\n",
      "Cluster 303: 1 embeddings\n",
      "Cluster 304: 1 embeddings\n",
      "Cluster 305: 1 embeddings\n",
      "Cluster 306: 1 embeddings\n",
      "Cluster 307: 1 embeddings\n",
      "Cluster 308: 1 embeddings\n",
      "Cluster 309: 1 embeddings\n",
      "Cluster 310: 1 embeddings\n",
      "Cluster 311: 1 embeddings\n",
      "Cluster 312: 1 embeddings\n",
      "Cluster 313: 1 embeddings\n",
      "Cluster 314: 1 embeddings\n",
      "Cluster 315: 1 embeddings\n",
      "Cluster 316: 1 embeddings\n",
      "Cluster 317: 1 embeddings\n",
      "Cluster 318: 1 embeddings\n",
      "Cluster 319: 1 embeddings\n",
      "Cluster 320: 1 embeddings\n",
      "Cluster 321: 1 embeddings\n",
      "Cluster 322: 1 embeddings\n",
      "Cluster 323: 1 embeddings\n",
      "Cluster 324: 1 embeddings\n",
      "Cluster 325: 1 embeddings\n",
      "Cluster 326: 1 embeddings\n",
      "Cluster 327: 1 embeddings\n",
      "Cluster 328: 1 embeddings\n",
      "Cluster 329: 1 embeddings\n",
      "Cluster 330: 1 embeddings\n",
      "Cluster 331: 1 embeddings\n",
      "Cluster 332: 1 embeddings\n",
      "Cluster 333: 1 embeddings\n",
      "Cluster 334: 1 embeddings\n",
      "Cluster 335: 1 embeddings\n",
      "Cluster 336: 1 embeddings\n",
      "Cluster 337: 1 embeddings\n",
      "Cluster 338: 1 embeddings\n",
      "Cluster 339: 1 embeddings\n",
      "Cluster 340: 1 embeddings\n",
      "Cluster 341: 1 embeddings\n",
      "Cluster 342: 1 embeddings\n",
      "Cluster 343: 1 embeddings\n",
      "Cluster 344: 1 embeddings\n",
      "Cluster 345: 1 embeddings\n",
      "Cluster 346: 1 embeddings\n",
      "Cluster 347: 1 embeddings\n",
      "Cluster 348: 1 embeddings\n",
      "Cluster 349: 1 embeddings\n",
      "Cluster 350: 1 embeddings\n",
      "Cluster 351: 1 embeddings\n",
      "Cluster 352: 1 embeddings\n",
      "Cluster 353: 1 embeddings\n",
      "Cluster 354: 1 embeddings\n",
      "Cluster 355: 1 embeddings\n",
      "Cluster 356: 1 embeddings\n",
      "Cluster 357: 1 embeddings\n",
      "Cluster 358: 1 embeddings\n",
      "Cluster 359: 1 embeddings\n",
      "Cluster 360: 1 embeddings\n",
      "Cluster 361: 1 embeddings\n",
      "Cluster 362: 1 embeddings\n",
      "Cluster 363: 1 embeddings\n",
      "Cluster 364: 1 embeddings\n",
      "Cluster 365: 1 embeddings\n",
      "Cluster 366: 1 embeddings\n",
      "Cluster 367: 1 embeddings\n",
      "Cluster 368: 1 embeddings\n",
      "Cluster 369: 1 embeddings\n",
      "Cluster 370: 1 embeddings\n",
      "Cluster 371: 1 embeddings\n",
      "Cluster 372: 1 embeddings\n",
      "Cluster 373: 1 embeddings\n",
      "Cluster 374: 1 embeddings\n",
      "Cluster 375: 1 embeddings\n",
      "Cluster 376: 1 embeddings\n",
      "Cluster 377: 1 embeddings\n",
      "Cluster 378: 1 embeddings\n",
      "Cluster 379: 1 embeddings\n",
      "Cluster 380: 1 embeddings\n",
      "Cluster 381: 1 embeddings\n",
      "Cluster 382: 1 embeddings\n",
      "Cluster 383: 1 embeddings\n",
      "Cluster 384: 1 embeddings\n",
      "Cluster 385: 1 embeddings\n",
      "Cluster 386: 1 embeddings\n",
      "Cluster 387: 1 embeddings\n",
      "Cluster 388: 1 embeddings\n",
      "Cluster 389: 1 embeddings\n",
      "Cluster 390: 1 embeddings\n",
      "Cluster 391: 1 embeddings\n",
      "Cluster 392: 1 embeddings\n",
      "Cluster 393: 1 embeddings\n",
      "Cluster 394: 1 embeddings\n",
      "Cluster 395: 1 embeddings\n",
      "Cluster 396: 1 embeddings\n",
      "Cluster 397: 1 embeddings\n",
      "Cluster 398: 1 embeddings\n",
      "Cluster 399: 1 embeddings\n",
      "Cluster 400: 1 embeddings\n",
      "Cluster 401: 1 embeddings\n",
      "Cluster 402: 1 embeddings\n",
      "Cluster 403: 1 embeddings\n",
      "Cluster 404: 1 embeddings\n",
      "Cluster 405: 1 embeddings\n",
      "Cluster 406: 1 embeddings\n",
      "Cluster 407: 1 embeddings\n",
      "Cluster 408: 1 embeddings\n",
      "Cluster 409: 1 embeddings\n",
      "Cluster 410: 1 embeddings\n",
      "Cluster 411: 1 embeddings\n",
      "Cluster 412: 1 embeddings\n",
      "Cluster 413: 1 embeddings\n",
      "Cluster 414: 1 embeddings\n",
      "Cluster 415: 1 embeddings\n",
      "Cluster 416: 1 embeddings\n",
      "Cluster 417: 1 embeddings\n",
      "Cluster 418: 1 embeddings\n",
      "Cluster 419: 1 embeddings\n",
      "Cluster 420: 1 embeddings\n",
      "Cluster 421: 1 embeddings\n",
      "Cluster 422: 1 embeddings\n",
      "Cluster 423: 1 embeddings\n",
      "Cluster 424: 1 embeddings\n",
      "Cluster 425: 1 embeddings\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 'embeddings'라는 텍스트 임베딩 목록이 있다고 가정합니다.\n",
    "# 먼저, 모든 임베딩 쌍 사이의 코사인 유사도 행렬을 계산합니다.\n",
    "cosine_sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# 응집 클러스터링 모델을 인스턴스화합니다.\n",
    "agg_clustering = AgglomerativeClustering(\n",
    "    n_clusters=None, # 알고리즘이 데이터를 기반으로 최적의 클러스터 수를 결정합니다.\n",
    "    distance_threshold=0.1, # 클러스터 간의 모든 쌍별 거리가 0.1보다 커질 때까지 클러스터를 형성합니다.\n",
    "    # affinity='precomputed', # 미리 계산된 거리 행렬(1 - 유사도 행렬)을 입력으로 제공합니다.\n",
    "    linkage='complete', # 구성 요소 간의 최대 거리를 기준으로 가장 작은 클러스터를 반복적으로 병합하여 클러스터를 형성합니다.\n",
    ")\n",
    "\n",
    "# 코사인 거리 행렬(1 - 유사도 행렬)에 모델을 맞춥니다.\n",
    "agg_clustering.fit(1 - cosine_sim_matrix)\n",
    "\n",
    "# 각 임베딩에 대한 클러스터 레이블을 가져옵니다.\n",
    "cluster_labels = agg_clustering.labels_\n",
    "\n",
    "# 각 클러스터의 임베딩 개수를 출력합니다.\n",
    "unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f'Cluster {label}: {count} embeddings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0727319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리의 가지치기 접근 방식에는 평균 길이 316.3 토큰을 가진 426 문서가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "pruned_documents = []\n",
    "for _label, count in zip(unique_labels, counts):\n",
    "    pruned_documents.append('\\n\\n'.join([text for text, label in zip(split, cluster_labels) if label == _label]))\n",
    "\n",
    "    \n",
    "avg_length = sum([len(tokenizer.encode(t)) for t in pruned_documents]) / len(pruned_documents)\n",
    "# print(f'Our pruning approach has {len(pruned_documents)} documents with average length {avg_length:.1f} tokens')\n",
    "print(f'우리의 가지치기 접근 방식에는 평균 길이 {avg_length:.1f} 토큰을 가진 {len(pruned_documents)} 문서가 있습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97f80b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45, 349, 350\n",
      "   survey  356, 357, 359, 360, 362, 363\n",
      "Spark  376\n",
      "spark_sklearn\n",
      "   reference link  405\n",
      "square matrix  77\n",
      "standard deviation  146\n",
      "standard normal distribution  133\n",
      "statistical modeling  226\n",
      "statistics  137, 201\n",
      "   measures of center  144\n",
      "   measures of relative standing  150, 153, 156\n",
      "   measures of variation  145, 148\n",
      "   measuring  144\n",
      "stock price\n",
      "   example  355\n",
      "stock prices\n",
      "   predicting, on social media  338\n",
      "   text sentiment analysis  338, 339\n",
      "structured data\n",
      "   about  33\n",
      "   versus unstructured data  33\n",
      "superset  87\n",
      "supervised learning  215\n",
      "supervised learning models  271\n",
      "supervised learning\n",
      "   classification  219\n",
      "   regression  219\n",
      "   types  219\n",
      "supervised machine learning  224\n",
      "T\n",
      "TensorFlow\n",
      "   about  368, 369, 370, 371, 372, 374\n",
      "   neural networks  368, 369, 370, 371, 372, 374   using  363, 364, 366, 367\n",
      "titanic dataset  68\n",
      "training error\n",
      "   versus cross-validation error  318, 320\n",
      "U\n",
      "underfitting  308\n",
      "unstructured data\n",
      "   about  33\n",
      "   versus structured data  33\n",
      "unsupervised learning  222\n",
      "   about  221, 271\n",
      "   reinforcement learning  223, 224\n",
      "   using  271\n",
      "unsupervised machine learning  225\n",
      "V\n",
      "vectors\n",
      "   about  75\n",
      "   answers  78\n",
      "   exercises  78\n",
      "verbal communication\n",
      "   about  206\n",
      "   data findings, presentation  207\n",
      "W\n",
      "World Health Organization (WHO)  39\n",
      "Y\n",
      "yelp dataset\n",
      "   about  59\n",
      "   DataFrame  61\n",
      "   qualitative data, exploration tips  62\n",
      "   series  62\n"
     ]
    }
   ],
   "source": [
    "print(pruned_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a46ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a3364dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_texts_to_pinecone(pruned_documents, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511c945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13cc8bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'How do z scores work?'\n",
    "\n",
    "results_from_pinecone = query_from_pinecone(query, top_k=5)\n",
    "\n",
    "for result_from_pinecone in results_from_pinecone:\n",
    "    print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "074fab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "이 예는 의미론적 텍스트 유사성(STS)을 위한 교차 인코더를 사용하여 쿼리와 말뭉치에서 가능한 모든\n",
    "문장과 의미론적 텍스트 유사성(STS)을 위한 교차 인코더를 사용하여 점수를 계산합니다.\n",
    "그런 다음 주어진 쿼리에 대해 가장 유사한 문장을 출력합니다.\n",
    "\"\"\"\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# 사전 학습된 크로스 인코더\n",
    "# cross_encoder = CrossEncoder('cross-encoder/mmarco-mMiniLMv2-L12-H384-v1')\n",
    "cross_encoder = CrossEncoder('jeffwan/mmarco-mMiniLMv2-L12-H384-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "414fc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_pinecone(query, top_k=3, re_rank=False, verbose=True):\n",
    "\n",
    "    results_from_pinecone = query_from_pinecone(query, top_k=top_k)\n",
    "    if not results_from_pinecone:\n",
    "        return []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Query:\", query)\n",
    "    \n",
    "    \n",
    "    final_results = []\n",
    "\n",
    "    if re_rank:\n",
    "        if verbose:\n",
    "            print('Document ID (Hash)\\t\\tRetrieval Score\\tCE Score\\tText')\n",
    "\n",
    "        sentence_combinations = [[query, result_from_pinecone['metadata']['text']] for result_from_pinecone in results_from_pinecone]\n",
    "\n",
    "        # 이러한 조합에 대한 유사도 점수를 계산합니다.\n",
    "        similarity_scores = cross_encoder.predict(sentence_combinations, activation_fct=nn.Sigmoid())\n",
    "\n",
    "        # 점수를 내림차순으로 정렬\n",
    "        sim_scores_argsort = reversed(np.argsort(similarity_scores))\n",
    "\n",
    "        # 점수를 인쇄합니다.\n",
    "        for idx in sim_scores_argsort:\n",
    "            result_from_pinecone = results_from_pinecone[idx]\n",
    "            final_results.append(result_from_pinecone)\n",
    "            if verbose:\n",
    "                print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{similarity_scores[idx]:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
    "        return final_results\n",
    "\n",
    "    if verbose:\n",
    "        print('Document ID (Hash)\\t\\tRetrieval Score\\tText')\n",
    "    for result_from_pinecone in results_from_pinecone:\n",
    "        final_results.append(result_from_pinecone)\n",
    "        if verbose:\n",
    "            print(f\"{result_from_pinecone['id']}\\t{result_from_pinecone['score']:.2f}\\t{result_from_pinecone['metadata']['text'][:50]}\")\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d89bcc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do z scores work?\n",
      "Document ID (Hash)\t\tRetrieval Score\tCE Score\tText\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99f541e2bd14c38ab54af7bd452f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49f68a5c8493ec2c0bf489821c21fc3b\t0.75\t0.00\thi\n"
     ]
    }
   ],
   "source": [
    "final_results = get_results_from_pinecone(query, top_k=3, re_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3c9922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do z scores work?\n",
      "Document ID (Hash)\t\tRetrieval Score\tCE Score\tText\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89d158e117e492d8df3e97d3f565231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49f68a5c8493ec2c0bf489821c21fc3b\t0.75\t0.00\thi\n"
     ]
    }
   ],
   "source": [
    "final_results = get_results_from_pinecone(query, top_k=10, re_rank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c018b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_texts_from_pinecone(pruned_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c716a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e1caf7",
   "metadata": {},
   "source": [
    "# BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62e28784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"boolq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6773457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'does ethanol take more energy make that produces',\n",
       " 'answer': False,\n",
       " 'passage': \"All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0221343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:09<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(0, len(dataset['validation']), 256)):\n",
    "    data_sample = dataset['validation'][idx:idx + 256]\n",
    "\n",
    "    passages = data_sample['passage']\n",
    "\n",
    "    upload_texts_to_pinecone(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c20f66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does the human body have a cannabinoid system\n",
      "Query: does the human body have a cannabinoid system\n",
      "Document ID (Hash)\t\tRetrieval Score\tCE Score\tText\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9cecaeb3bd4c388437b4aa82a0eaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49f68a5c8493ec2c0bf489821c21fc3b\t0.73\t0.17\thi\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "query = sample(dataset['validation']['question'], 1)[0]\n",
    "print(query)\n",
    "final_results = get_results_from_pinecone(query, top_k=3, re_rank=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1e27222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7c04981525ffb6cb14f43ec062beafef'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_to_hash = {data['question']: my_hash(data['passage']) for data in dataset['validation']}\n",
    "\n",
    "q_to_hash[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a63ec53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super_glue_metric = load('super_glue', 'boolq') # 정확도만 확인합니다.\n",
    "\n",
    "# 1000개의 유효성 검사 데이터 포인트에 대한 성능 재순위를 테스트해 보겠습니다.\n",
    "# 여기서는 속도를 높이기 위해 Pinecone을 사용할 수 없습니다.\n",
    "# 하지만 Pinecone으로 파이프라인의 지연 시간을 테스트하기에도 좋은 시기입니다.\n",
    "val_sample = dataset['validation']#[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3a147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfea2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3270/3270 [27:52<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without re-ranking: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Pinecone의 지연 시간이 일관되게 유지되도록 top_k를 동일하게 유지합니다.\n",
    "# 그리고 유일한 큰 시간 차이는 리랭킹에서 발생합니다.\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash = get_results_from_pinecone(question, top_k=1, re_rank=False, verbose=False)[0]['id']\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append(retrieved_hash == correct_hash)\n",
    "    \n",
    "accuracy = sum(predictions)/len(predictions)\n",
    "\n",
    "print(f'Accuracy without re-ranking: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98413a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████████████████▎  | 3173/3270 [29:42<00:48,  1.99it/s]"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Pinecone의 지연 시간이 일관되게 유지되도록 top_k를 동일하게 유지합니다.\n",
    "# 그리고 유일한 큰 시간 차이는 리랭킹에서 발생합니다.\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash = get_results_from_pinecone(question, top_k=3, re_rank=True, verbose=False)[0]['id']\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append(retrieved_hash == correct_hash)\n",
    "    \n",
    "accuracy = sum(predictions)/len(predictions)\n",
    "\n",
    "print(f'Accuracy with re-ranking: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acf707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순위 재조정 시와 그렇지 않은 경우의 시간 차이에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfebd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ca98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ranking(query, cross_encoder, top_k=3):\n",
    "    results_from_pinecone = query_from_pinecone(query, top_k=top_k)\n",
    "    sentence_combinations = [[query, result_from_pinecone['metadata']['text']] for result_from_pinecone in results_from_pinecone]\n",
    "    similarity_scores = cross_encoder.predict(sentence_combinations)\n",
    "    sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
    "    re_ranked_final_result = results_from_pinecone[sim_scores_argsort[0]]\n",
    "    return results_from_pinecone[0]['id'], re_ranked_final_result['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4010029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 다른 크로스 인코더 시도하기\n",
    "# sentence-transformers/multi-qa-mpnet-base-cos-v1\n",
    "newer_cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34ac11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104305e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print_every = 50\n",
    "predictions = []\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash, reranked_hash = eval_ranking(question, newer_cross_encoder, top_k=3)\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append((retrieved_hash == correct_hash, reranked_hash == correct_hash))\n",
    "    i += 1\n",
    "    if i % print_every == 0:\n",
    "        print(f'Step {i}')\n",
    "        raw_accuracy = sum([p[0] for p in predictions])/len(predictions)\n",
    "        reranked_accuracy = sum([p[1] for p in predictions])/len(predictions)\n",
    "\n",
    "        print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "        print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_accuracy = sum([p[0] for p in predictions])/len(predictions)\n",
    "reranked_accuracy = sum([p[1] for p in predictions])/len(predictions)\n",
    "\n",
    "print(f'Using cross-encoder: {newer_cross_encoder.config._name_or_path}')\n",
    "print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea30153c",
   "metadata": {},
   "source": [
    "# Fine-tuning re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/ms_marco/train_cross-encoder_scratch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508edaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from random import shuffle\n",
    "\n",
    "shuffled_training_passages = dataset['train']['passage'].copy()\n",
    "shuffle(shuffled_training_passages)\n",
    "\n",
    "\n",
    "train_samples = [\n",
    "  InputExample(texts=[d['question'], d['passage']], label=1) for d in dataset['train']\n",
    "]\n",
    "\n",
    "# 부정적인 예제 추가\n",
    "train_samples += [\n",
    "  InputExample(texts=[d['question'], shuffled_training_passages[i]], label=0) for i, d in enumerate(dataset['train'])\n",
    "]\n",
    "\n",
    "shuffle(train_samples)\n",
    "\n",
    "# 내 데이터에 과적합의 위험이 있지만 원할 수도 있습니다. \n",
    "# 충분한 입력 및 출력 유효성 검사와 결합하면 내 데이터에 과적합한 모델을 사용하여 실행 가능한 제품을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7826e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda')  # NVIDIA GPU\n",
    "\n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', num_labels=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7eaa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(train_samples[0].texts, activation_fct=nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator, CEBinaryClassificationEvaluator\n",
    "import math\n",
    "import torch\n",
    "from random import sample\n",
    "\n",
    "logger.setLevel(logging.DEBUG)  # just to get some logs\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "model_save_path = './fine_tuned_ir_cross_encoder'\n",
    "\n",
    "# train_samples = sample(train_samples, 1000)\n",
    "\n",
    "# int(len(train_samples)*.8)\n",
    "train_dataloader = DataLoader(train_samples[:int(len(train_samples)*.8)], shuffle=True, batch_size=32)\n",
    "\n",
    "# 훈련 성능을 위한 평가자\n",
    "evaluator = CEBinaryClassificationEvaluator.from_input_examples(train_samples[-int(len(train_samples)*.8):], name='test')\n",
    "\n",
    "# 워밍업 단계에 대한 경험 법칙\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 워밍업을 위한 훈련 데이터의 10%\n",
    "print(f\"Warmup-steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ##### 모델을 로드하고 테스트 세트에서 평가합니다.\n",
    "# print(evaluator(model))\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    # loss_fct=losses.nn.CrossEntropyLoss(),\n",
    "    loss_fct= nn.CrossEntropyLoss(),\n",
    "    activation_fct=nn.Sigmoid(),\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    "    # use_amp=True, # GPU 사용시\n",
    "    use_amp=False,  # CPU 사용시\n",
    ")\n",
    "\n",
    "# # #### 모델을 로드하고 테스트 세트에서 평가하기\n",
    "# print(evaluator(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca59b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오픈 소스에서도 더 미세 조정된 버전을 실행하여 일치시킬 수 있을까요?\n",
    "# 여기서 더 잘 작동하는지에 따라 다릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f747537",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = CrossEncoder(model_save_path)\n",
    "\n",
    "print(finetuned.predict(['hello', 'hi'], activation_fct=nn.Sigmoid()))\n",
    "print(finetuned.predict(['hello', 'hi'], activation_fct=nn.Identity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1f756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf736e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 미세 조정된 크로스 인코더 사용해보기\n",
    "logger.setLevel(logging.CRITICAL)  # just to suppress some logs\n",
    "from tqdm import tqdm\n",
    "\n",
    "i = 0\n",
    "print_every = 50\n",
    "predictions = []\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash, reranked_hash = eval_ranking(question, finetuned, top_k=3)\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append((retrieved_hash == correct_hash, reranked_hash == correct_hash))\n",
    "    i += 1\n",
    "    if i % print_every == 0:\n",
    "        print(f'Step {i}')\n",
    "        raw_accuracy = sum([p[0] for p in predictions])/len(predictions)\n",
    "        reranked_accuracy = sum([p[1] for p in predictions])/len(predictions)\n",
    "\n",
    "        print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "        print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재랭킹은 2번의 에포크 이후 약간 개선되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_accuracy = sum([p[0] for p in predictions])/len(predictions)\n",
    "reranked_accuracy = sum([p[1] for p in predictions])/len(predictions)\n",
    "\n",
    "print(f'Using cross-encoder: {finetuned.config._name_or_path}')\n",
    "print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92875bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b414c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone.delete_index(INDEX_NAME)  # delete the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14809e",
   "metadata": {},
   "source": [
    "# OPEN SOURCE ALTERNATIVE TO EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99138055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')\n",
    "\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "doc_emb = model.encode(docs, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "doc_emb.shape#  == ('2, 768')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1140c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#쿼리 및 문서 인코딩\n",
    "docs = dataset['validation']['passage']\n",
    "doc_emb = model.encode(docs, batch_size=32, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0afee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "query = sample(dataset['validation']['question'], 1)[0]\n",
    "print(query)\n",
    "final_results = get_results_from_pinecone(query, top_k=3, re_rank=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c71fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "query_emb = model.encode(query)\n",
    "\n",
    "#쿼리와 모든 문서 임베딩 사이의 도트 점수를 계산합니다.\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "#문서와 점수 결합\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#점수에 따른 내림차순 정렬\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#구절 및 점수 출력\n",
    "for doc, score in doc_score_pairs[:3]:\n",
    "    print(score, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533d9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93280be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.CRITICAL)  # 일부 로그만 출력\n",
    "\n",
    "def eval_ranking_open_source(query, cross_encoder, top_k=3):\n",
    "    # query_emb = np.array(get_embedding(query))\n",
    "    query_emb = model.encode(query)\n",
    "\n",
    "    #쿼리와 모든 문서 임베딩 사이의 도트 점수를 계산합니다.\n",
    "    scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "    #문서와 점수 결합\n",
    "    doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "    #점수에 따른 내림차순 정렬\n",
    "    doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    retrieved_hash = my_hash(doc_score_pairs[0][0])\n",
    "    if cross_encoder:\n",
    "        sentence_combinations = [[query, doc_score_pair[0]] for doc_score_pair in doc_score_pairs]\n",
    "        similarity_scores = cross_encoder.predict(sentence_combinations)\n",
    "        sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
    "        reranked_hash = my_hash(doc_score_pairs[sim_scores_argsort[0]][0])\n",
    "    else:\n",
    "        reranked_hash = None\n",
    "    return retrieved_hash, reranked_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f198cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ranking_open_source(query, finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf0c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "i = 0\n",
    "print_every = 50\n",
    "predictions = []\n",
    "for question in tqdm(val_sample['question']):\n",
    "    retrieved_hash, reranked_hash = eval_ranking_open_source(question, finetuned, top_k=3)\n",
    "    correct_hash = q_to_hash[question]\n",
    "    predictions.append((retrieved_hash == correct_hash, reranked_hash == correct_hash))\n",
    "    i += 1\n",
    "    if i % print_every == 0:\n",
    "        print(f'Step {i}')\n",
    "        raw_accuracy = sum([p[0] for p in predictions])/len(predictions)\n",
    "        reranked_accuracy = sum([p[1] for p in predictions])/len(predictions)\n",
    "\n",
    "        print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "        print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaeb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_accuracy = sum([p[0] for p in predictions])/len(predictions)\n",
    "reranked_accuracy = sum([p[1] for p in predictions])/len(predictions)\n",
    "\n",
    "print(f'Using cross-encoder: {finetuned.config._name_or_path}')\n",
    "print(f'Accuracy without re-ranking: {raw_accuracy}')\n",
    "print(f'Accuracy with re-ranking: {reranked_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca7d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
